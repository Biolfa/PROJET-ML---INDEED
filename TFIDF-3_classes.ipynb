{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "import re\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "from nltk import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "from wordcloud import WordCloud\n",
    "\n",
    "import unidecode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=pd.read_csv(\"salary_indeed.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Création Fonction Split Salary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_salary(row):\n",
    "    salary = row[\"Salary\"]\n",
    "    if \"-\" in salary:\n",
    "        split = salary.split(\"-\")\n",
    "        salary_min = split[0]\n",
    "        salary_max = split[1]\n",
    "    else:\n",
    "        salary_min = salary\n",
    "        salary_max = salary\n",
    "    \n",
    "    row[\"salary_min\"] = salary_min.replace(\"€\",\"\")\\\n",
    "                                  .replace(\"par an\",\"\")\\\n",
    "                                  .replace(\"par mois\",\"\")\\\n",
    "                                  .replace(\"par semaine\",\"\")\\\n",
    "                                  .replace(\"par jour\",\"\")\\\n",
    "                                  .replace(\"par heure\",\"\")\\\n",
    "                                  .replace(\"\\xa0\",\"\")\n",
    "    row[\"salary_max\"] = salary_max.replace(\"€\",\"\")\\\n",
    "                                  .replace(\"par an\",\"\")\\\n",
    "                                  .replace(\"par mois\",\"\")\\\n",
    "                                  .replace(\"par semaine\",\"\")\\\n",
    "                                  .replace(\"par jour\",\"\")\\\n",
    "                                  .replace(\"par heure\",\"\")\\\n",
    "                                  .replace(\"\\xa0\",\"\")\n",
    "    \n",
    "    if \"an\" in row[\"Salary\"]:\n",
    "        row[\"salary_period\"] = \"year\"\n",
    "\n",
    "    if \"mois\" in row[\"Salary\"]:\n",
    "        if float(row[\"salary_min\"]) < 1500:\n",
    "            row[\"salary_min\"] = float(row[\"salary_min\"])\n",
    "            row[\"salary_max\"] = float(row[\"salary_max\"])\n",
    "            row[\"salary_period\"] = \"month\"\n",
    "        else:\n",
    "            row[\"salary_min\"] = float(row[\"salary_min\"])*12\n",
    "            row[\"salary_max\"] = float(row[\"salary_max\"])*12\n",
    "            row[\"salary_period\"] = \"year\"\n",
    "    \n",
    "    if \"semaine\" in row[\"Salary\"]:\n",
    "        row[\"salary_min\"] = float(row[\"salary_min\"])\n",
    "        row[\"salary_max\"] = float(row[\"salary_max\"])\n",
    "        row[\"salary_period\"] = \"week\"\n",
    "\n",
    "    if \"jour\" in row[\"Salary\"]:\n",
    "        row[\"salary_min\"] = float(row[\"salary_min\"])\n",
    "        row[\"salary_max\"] = float(row[\"salary_max\"])\n",
    "        row[\"salary_period\"] = \"day\"\n",
    "\n",
    "    if \"heure\" in row[\"Salary\"]:\n",
    "        row[\"salary_min\"] = float(row[\"salary_min\"].replace(\",\",\".\"))\n",
    "        row[\"salary_max\"] = float(row[\"salary_max\"].replace(\",\",\".\"))\n",
    "        row[\"salary_period\"] = \"hour\"\n",
    "        \n",
    "    return row"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Création des colonnes salary max et salary min"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stop_words = stopwords.words('french')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Mettre en minuscule\n",
    "2. Remplacer les ponctuations (sauf '+') par des espaces : `[^\\w|\\s|+]` mais aussi les '|' et '\\_' : `[_|\\|]`\n",
    "3. Remplacer les lettres accentuées par des lettres sans accents\n",
    "4. Remplacer les lettres seules (sauf les lettres c et r (langages de programmation)) par des espaces : `\\b[abd-qs-z]\\b`\n",
    "5. Remplacer les nombres qui ont 2 chiffres ou plus par des espaces : `\\d{2,}`\n",
    "6. Splitter la chaîne de caractères en une liste de mots\n",
    "7. Créer une nouvelle liste sans les stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocessing_text(text, stopwords):\n",
    "    text = text.lower()\n",
    "    text = re.sub(r'[^\\w|\\s|+]', ' ', text)\n",
    "    text = re.sub(r'[_|\\|]', ' ', text)\n",
    "    text = unidecode.unidecode(text)\n",
    "    text = re.sub(r'\\b[abd-qs-z]\\b', ' ', text)\n",
    "    text = re.sub(r'\\d{2,}', ' ', text)\n",
    "\n",
    "    # STOPWORDS\n",
    "    tokenized_words = word_tokenize(text)\n",
    "    tokenized_words = [word for word in tokenized_words if word not in stopwords]\n",
    "\n",
    "    return tokenized_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_salary = df[~df.Salary.isna()]\n",
    "\n",
    "df_salary = df_salary.apply(lambda column: column.apply(preprocessing_text, args=(stop_words,))\n",
    "                                          if column.name in ['Title', 'Description']\n",
    "                                          else column)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_salary = df_salary.apply(split_salary, axis=1)\n",
    "df_salary[\"salary_min\"]=pd.to_numeric(df_salary[\"salary_min\"],'coerce')\n",
    "df_salary[\"salary_max\"]=pd.to_numeric(df_salary[\"salary_max\"],'coerce')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_salary.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Création colonne salary mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_salary[\"salary_mean\"] = (df_salary[\"salary_min\"]+df_salary[\"salary_max\"])/2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_salary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Je ne prends que les salaires qui sont 'par an' "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_salary = df_salary[df_salary.salary_period == 'year']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Quantiles salary min"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_salary.salary_min.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Quantiles salary max"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_salary.salary_max.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Quantiles salary mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_salary.salary_mean.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tercile_1 = np.quantile(df_salary.salary_mean, 1/3)\n",
    "tercile_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tercile_2 = np.quantile(df_salary.salary_mean, 2/3)\n",
    "tercile_2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Création colonne class label par rapport aux quantiles salary mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def classification(x):\n",
    "    if x <= tercile_1:\n",
    "        label = 1\n",
    "    elif x <= tercile_2:\n",
    "        label = 2\n",
    "    else:\n",
    "        label = 3\n",
    "    return label\n",
    "\n",
    "df_salary[\"salary_label\"] = df_salary[\"salary_mean\"].apply(classification)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_salary.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Création des df par tranches label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_1 = df_salary[df_salary[\"salary_label\"]==1]\n",
    "label_2 = df_salary[df_salary[\"salary_label\"]==2]\n",
    "label_3 = df_salary[df_salary[\"salary_label\"]==3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_salary.Department_Search.value_counts(normalize=True) * 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_salary.Job_Search.value_counts(normalize=True) * 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_1.Department_Search.value_counts(normalize=True) * 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_1.Job_Search.value_counts(normalize=True) * 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_2.Department_Search.value_counts(normalize=True) * 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_2.Job_Search.value_counts(normalize=True) * 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_3.Department_Search.value_counts(normalize=True) * 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "label_3.Job_Search.value_counts(normalize=True) * 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tag_title_1 = label_1[\"Title\"]\n",
    "tag_title_2 = label_2[\"Title\"]\n",
    "tag_title_3 = label_3[\"Title\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# créer un dictionnaire avec la frequence de chaque mot de tag_title1\n",
    "# on va ordonner par la valeur du dictionnaire en ordre descendant\n",
    "\n",
    "result_1 = tag_title_1.apply(Counter).sum().items()\n",
    "result_1 = sorted(result_1, key=lambda kv : kv[1], reverse=True)\n",
    "\n",
    "result_2 = tag_title_2.apply(Counter).sum().items()\n",
    "result_2 = sorted(result_2, key=lambda kv : kv[1], reverse=True)\n",
    "\n",
    "result_3 = tag_title_3.apply(Counter).sum().items()\n",
    "result_3 = sorted(result_3, key=lambda kv : kv[1], reverse=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Je crée le dictionnaire qui associe la frequece de chaque mot sur chaque df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_series_1 = dict(result_1)\n",
    "result_series_2 = dict(result_2)\n",
    "result_series_3 = dict(result_3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_series_1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Visualisation du wordcloud title de chaque df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wordcloud_1 = WordCloud(max_words=50).generate_from_frequencies(result_series_1)\n",
    "wordcloud_2 = WordCloud(max_words=50).generate_from_frequencies(result_series_2)\n",
    "wordcloud_3 = WordCloud(max_words=50).generate_from_frequencies(result_series_3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize = (25, 30))\n",
    "\n",
    "plt.subplot(3, 1, 1)\n",
    "plt.imshow(wordcloud_1, interpolation=\"bilinear\")\n",
    "plt.axis(\"off\")\n",
    "\n",
    "plt.subplot(3, 1, 2)\n",
    "plt.imshow(wordcloud_2, interpolation=\"bilinear\")\n",
    "plt.axis(\"off\")\n",
    "\n",
    "plt.subplot(3, 1, 3)\n",
    "plt.imshow(wordcloud_3, interpolation=\"bilinear\")\n",
    "plt.axis(\"off\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tag_desc_1 = label_1[\"Description\"]\n",
    "tag_desc_2 = label_2[\"Description\"]\n",
    "tag_desc_3 = label_3[\"Description\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tag_desc_3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# création des dictionnaires qui à chaque mot associe sa frequence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "desc_1 = tag_desc_1.apply(Counter).sum().items()\n",
    "desc_1 = sorted(desc_1, key=lambda kv : kv[1], reverse=True) \n",
    "dict_desc_1 = {k: v for k,v in desc_1}\n",
    "\n",
    "desc_2 = tag_desc_2.apply(Counter).sum().items()\n",
    "desc_2 = sorted(desc_2, key=lambda kv : kv[1], reverse=True) \n",
    "dict_desc_2 = {k: v for k,v in desc_2}\n",
    "\n",
    "desc_3 = tag_desc_3.apply(Counter).sum().items()\n",
    "desc_3 = sorted(desc_3, key=lambda kv : kv[1], reverse=True) \n",
    "dict_desc_3 = {k: v for k,v in desc_3}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Visualisation du wordcloud job_desc pour chaque df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wordcloud6 = WordCloud(max_words=50).generate_from_frequencies(dict_desc_1)\n",
    "wordcloud7 = WordCloud(max_words=50).generate_from_frequencies(dict_desc_2)\n",
    "wordcloud8 = WordCloud(max_words=50).generate_from_frequencies(dict_desc_3)\n",
    "\n",
    "figure = plt.figure(figsize = (25, 30))\n",
    "plt.figure(1)\n",
    "plt.subplot(3, 1, 1)\n",
    "plt.imshow(wordcloud6, interpolation=\"bilinear\")\n",
    "plt.axis(\"off\")\n",
    "\n",
    "plt.subplot(3, 1, 2)\n",
    "plt.imshow(wordcloud7, interpolation=\"bilinear\")\n",
    "plt.axis(\"off\")\n",
    "\n",
    "plt.subplot(3, 1, 3)\n",
    "plt.imshow(wordcloud8, interpolation=\"bilinear\")\n",
    "plt.axis(\"off\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## prediction salaire avec job desc brut seulement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_desc = df_salary.Description.apply(\" \".join)\n",
    "y = df_salary.salary_label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_desc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer = TfidfVectorizer(ngram_range=(1, 4))\n",
    "vectorizer.fit(X_desc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(vectorizer.get_feature_names())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_desc_trans = pd.DataFrame(vectorizer.transform(X_desc).todense(), columns=vectorizer.get_feature_names())\n",
    "X_desc_trans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "np.asmatrix(X_desc_trans)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_counts = X_desc_trans.sum(axis=0)\n",
    "word_counts.sort_values(ascending = False).head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(np.asmatrix(X_desc_trans), y, stratify=y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rfc = RandomForestClassifier(n_estimators=5, random_state=42)\n",
    "rfc.fit(X_train, y_train)\n",
    "\n",
    "rfc.score(X_test,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rfc.score(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_importances = pd.DataFrame(rfc.feature_importances_,\n",
    "                                   index = X_desc_trans.columns).reset_index()\n",
    "feature_importances.columns = ['feature', 'importance']\n",
    "\n",
    "feature_importances.sort_values('importance', ascending=False).head(30)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prédiction salaire avec Title seulement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_title = df_salary.Title.apply(\" \".join)\n",
    "y = df_salary.salary_label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer_2 = TfidfVectorizer(ngram_range=(1, 4))\n",
    "vectorizer_2.fit(X_title)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(vectorizer_2.get_feature_names())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_title_trans = pd.DataFrame(vectorizer_2.transform(X_title).todense(), columns=vectorizer_2.get_feature_names())\n",
    "X_title_trans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_counts2 = X_title_trans.sum(axis=0)\n",
    "word_counts2.sort_values(ascending = False).head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train2, X_test2, y_train2, y_test2 = train_test_split(np.asmatrix(X_title_trans), y, random_state=42, stratify=y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rfc = RandomForestClassifier(7, random_state=42)\n",
    "rfc.fit(X_train2, y_train2)\n",
    "\n",
    "rfc.score(X_test2,y_test2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rfc.score(X_train2,y_train2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_importances = pd.DataFrame(rfc.feature_importances_,\n",
    "                                   index = X_title_trans.columns).reset_index()\n",
    "feature_importances.columns = ['feature', 'importance']\n",
    "\n",
    "feature_importances.sort_values('importance', ascending=False).head(20)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
